{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reposiotry to create Hugging Face Dataset for and from my blog\n",
    "\n",
    "It includes all blog posts from [philschmid.de](https://www.philschmid.de) as `jsonlines` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `*.mdx` files from local path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "{'title': 'Google Colab the free GPU/TPU Jupyter Notebook Service', 'date': '2020-02-26', 'tags': ['Machine Learning'], 'summary': 'A Short Introduction to Google Colab as a free Jupyter notebook service from Google. Learn how to use Accelerated Hardware like GPUs and TPUs to run your Machine learning completely for free in the cloud.', 'content': '## What is Google Colab\\n\\n**Google Colaboratory** or â€žColabâ€œ for short is a free Jupyter notebook service from Google. It requires no setup and\\nruns entirely in the cloud. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access\\npowerful computing resources like TPUs and GPUs all for free through your browser. All major Python libraries like\\n[Tensorflow](https://www.tensorflow.org/), [Scikit-learn](https://scikit-learn.org/), [PyTorch](https://pytorch.org/),\\n[Pandas](https://pandas.pydata.org/), etc. are pre-installed. Google Colab requires no configuration, you only need a\\nGoogle Account and then you are good to go. Your notebooks are stored in your [Google Drive](https://drive.google.com/),\\nor can be loaded from [GitHub](https://github.com/). Colab notebooks can be shared just as you would with Google Docs or\\nSheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive\\n[file sharing instructions](https://support.google.com/drive/answer/2494822?co=GENIE.Platform%3DDesktop&hl=en).\\n\\nFor more informations you can look into the official FAQ from Google Research. You can find the FAQ under\\n[Colaboratory â€“ Google](https://research.google.com/colaboratory/faq.html) or you can have a look at the introduction\\nvideo [Get started with Google Colaboratory (Coding TensorFlow) - YouTube](https://www.youtube.com/watch?v=inN8seMm7UI)\\n\\n## Is it free?\\n\\n**Yes, it is completely free of charge** you only need a Google account, which probably all of you have. You can use the\\nCPU-, GPU- & TPU-Runtime completely for free. Google also offer in some cases the opportunity to extend the runtime into\\none with 25GB of memory completely for free.\\n\\nRecently Google Introduced â€žColab Proâ€œ which is a paid version for \\\\$9.99/month. With â€žColab Proâ€œ you have prior access\\nto GPU and TPUs and also higher memory. You can be up to 24 hours connected to your notebooks in comparison in the free\\nversion the connection limit is 12h per day. For more information read here:\\n[Google Colab Pro](https://colab.research.google.com/signup?utm_source=faq&utm_medium=link&utm_campaign=why_arent_resources_guaranteed).\\n\\n## Ressources and Runtimes\\n\\n| Type   | Size                                  |\\n| ------ | ------------------------------------- |\\n| CPU    | 2x                                    |\\n| Memory | 12.52GB                               |\\n| GPU    | T4 with 7,98GB or K80 with 11,97GB    |\\n| TPUv2  | 8units                                |\\n| Disk   | at least 25GB will increase as needed |\\n\\n## How to use accelerated hardware\\n\\nChanging hardware runtime is as easy as it could get. You just have to navigate from â€žRuntimeâ€œ -> â€žchange runtime typeâ€œ\\nand select your preferred accelerated hardware type GPU or TPU.\\n\\n![change-runtime](/static/blog/google-cola-the-free-gpu-jupyter/change-runtime.gif)\\n\\n## How to get started\\n\\nIn the following section, I will describe and show some of the best features Google Colab has to offer. I created a\\n[Colab Notebook](https://colab.research.google.com/drive/1nwJ0BQjZACbGbt-AfG93LjJNT05mp4gw) with all of the features for\\nyou to lookup.\\n\\n### Creating a Colab Notebook\\n\\nYou can create a Colab notebook directly in the [Colab Environment](https://colab.research.google.com/) or through your\\nGoogle Drive.\\n\\n### Access your google drive storage in your Colab notebook by mounting it\\n\\nIf you want to mount your Google Drive to your notebook you simply have to execute the snippet below. After you executed\\nit, you will see a URL where you have to login to your Google account and authorize Google Colab to access your Drive\\nStorage. Afterward, you can copy the key from the link into the displayed input-field in the Colab notebook.\\n\\n```python\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive/\\')\\n```\\n\\nYou can show your files with `!ls /content/drive` or use the navigation on the left side.\\n\\n### Upload and Download local files to your Colab notebook\\n\\nYou can easily upload and download files from your local machine by executing `files.upload()`, which creates a HTML\\nfile input-field and `files.download()`.\\n\\n#### Upload\\n\\n```python\\nfrom google.colab import files\\nuploaded = files.upload()\\n```\\n\\n#### Dowlnload\\n\\n```python\\nfrom google.colab import files\\nfiles.download(\"File Name\")\\n```\\n\\n##### Download a complete folder by zipping it\\n\\n```python\\nfrom google.colab import files\\nimport zipfile\\nimport sys\\nfoldername = \"test_folder\"\\nzipfile.ZipFile(f\\'{foldername}.zip\\', \\'w\\', zipfile.ZIP_DEFLATED)\\nfiles.download(f\\'{foldername}.zip\\')\\n```\\n\\n### Change your directory permanently\\n\\nYou can change your directory permanently from `/content` to something you like by executing `%cd path` in a cell. This\\nis very useful if you clone your git repository into your colab notebook.\\n\\n```python\\n%cd path\\n```\\n\\n### Show an image in Colab\\n\\nYou can show pictures inline as you do it in jupyter with this simple snippet\\n\\n```python\\nfrom IPython.display import Image, display\\n\\ndisplay(Image(\\'image.jpg\\'))\\n```\\n\\n### Advanced Pandas table\\n\\nGoogle Colab offers an improved view of data frames in addition to the normal, familiar jupyter notebook view, in where\\nyou can filter columns directly without using python. You can even search for a range in date fields. You can use it by\\nexecuting one line of code.\\n\\n```python\\n%load_ext google.colab.data_table\\n```\\n\\n![pandas-extended-view](/static/blog/google-cola-the-free-gpu-jupyter/pandas-extended-view.jpg)\\n\\n### How to use git in Colab\\n\\nGoogle Colab provides a lot of benefits, but one downside is you have to save your notebook to your google drive.\\nNormally you use some kind of git tool. The easiest way to overcome this problem is either by copying your notebook from\\nGitHub into your Colab Environment with this\\n[easy copy integration for notebooks](https://colab.research.google.com/github/) or you can use CLI commands to load\\nyour private and public repository into your git. The only problem with using GitHub Repositories in your Colab is you\\ncannot push back to your Repository, you have to save it manually (â€žFileâ€œ -> â€žsave a Copy as Github Gistâ€œ or â€žSave a\\ncopy on Githubâ€œ). If you want to integrate your repository directly you have to set up git in your Colab environment\\nlike you normally do on your local machine. Chella wrote an article in Towards Data Science on how to do it.\\n[From Git to Colab, via SSH - Towards Data Science](https://towardsdatascience.com/using-git-with-colab-via-ssh-175e8f3751ec)\\n\\n```\\n# git clone private repository\\n!git clone https://username:password@github.com/username/repository.git\\n\\n# git clone public repository\\n!git clone https://github.com/fastai/courses.git\\n```\\n\\nAn extra tip is after you cloned your repository, you can permanently change directory to the repository by executing\\n`%cd /content/your_repostiory_name`. After that, every cell will be executed in the directory of your repository.\\n\\n### Execute CLI commands\\n\\nYou can execute CLI commands for example, to install python package, update python package or run bash scripts just by\\nputting `!` before the command.\\n\\n```\\n!pip install fastai\\n```\\n\\n### Customize Shortcuts and changing Theme\\n\\nYou can customize Shortcuts by navigating from \"Toolsâ€œ -> â€žKeyboard shortcutsâ€¦â€œ or if you want to change your theme you\\nmust navigate from â€žToolsâ€œ -> â€žSettingsâ€œ and under â€žSiteâ€œ you can change it.\\n![customizing_shortcuts_and_changing_theme](/static/blog/google-cola-the-free-gpu-jupyter/customizing_shortcuts_and_changing_theme.gif)\\n\\n---\\n\\nThanks for reading my first blog post about Google Colaboratory.  \\nSee you soon ðŸ˜Š'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import frontmatter\n",
    "\n",
    "blog_post_directory = \"/Users/philipp/Projects/personal/blog/philschmid-de-v2/data/blog\"\n",
    "blog_post_directory = Path(blog_post_directory)\n",
    "\n",
    "# create list of all files in the directory\n",
    "list_of_files = [file for file in blog_post_directory.glob(\"**/*.mdx\")]\n",
    "\n",
    "# iterate over all files and read with frontmatter into dictonary\n",
    "dataset_list = []\n",
    "for file in list_of_files:\n",
    "    post = frontmatter.load(file)\n",
    "    dataset_list.append({\n",
    "        \"title\": post[\"title\"],\n",
    "        \"date\": post[\"date\"],\n",
    "        \"tags\": post[\"tags\"],\n",
    "        \"summary\": post[\"summary\"],        \n",
    "        \"content\": post.content}\n",
    ")\n",
    "\n",
    "print(\"sample\")\n",
    "print(dataset_list[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create Hugging Face Dataset from dictonary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# create dataset from list\n",
    "dataset = Dataset.from_list(dataset_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push dataset to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 170.78ba/s]\n",
      "Upload 1 LFS files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.95s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.66s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"philschmid/philschmid-de-blog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fcf248a74081676ead7e77f54b2c239ba2921b952f7cbcdbbe5427323165924"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
